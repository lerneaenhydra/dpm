function varargout = dpm(varargin)
% DPM(inp, mod_consts) Simple dynamic programming solver for arbitrary
% continuous-valued problems represented with ODEs. Solves problems of the
% form:
%	
%	min C(x(k), u(k)) for k = [0, K]
%
%	subject to
%
%	x(k+t) = f(x(k), u(k))
%
% where x(k) and u(k) represent the sampled state and control variable
% values at some time k.
%
% This dynamic programming solver differs from the textbook DP solver in
% the following ways;
%	- The search range for state and control variables is iteratively
%	decreased following a mostly typical iterative dynamic programming
%	(IDP) implementation. This solver differs from the typical IDP solver
%	by allowing the grid size to increase slightly in the event that the
%	feasible solution can be found after decreasing the search grid
%	extents.
%	- For loosely coupled multidimensional problems, an approximate
%	solution generated by some n-1-dimensional problem can be used to
%	reduce the search space for the n-dimensional problem, significantly
%	reducing the time needed to arrive to a solution.
%	- An optional regularization term can by added and/or scale the cost
%	function for tested states that are within some adjustable distance
%	to infeasible state(s). This regularization term sigificanlty increases
%	the ability for the DP solver to generate a feasible control
%	trajectory for applications where the optimal control trajectory lies
%	along a boundary of infeasibility (eg. bang-bang control).
%
% Use the call 'inp = dpm()' to return a structure containing the fields
% required by the dpm solver.
%
% Use the call '[inp, grid_subset] = dpm()' to return the previously
% described structure as well as an empty structure of the form used to
% configure limiting the search space for grid variable(s).
%
% Use the call [res, grid, t, c, map] = dpm(inp, mod_consts, h_iterplot)
% to solve the dynamic programming problem.
%
% Inputs;	inp		Structure with all configuration for the DP solver.
%					Must contain the following fields;
%
%					.prb		All problem-related options
%						.T_s	The sample period for the system to solve
%						.N_x	The number of state variables
%						.N_u	The number of control variables
%						.N_t	The number of samples to process. This
%								gives the total simulation time by T_s *
%								(N_t - 1).
%
%						Note; all the following fields must be matrices of
%						size [N_x, 1].
%						.X_l	The lower box bound for all state
%								variables.
%						.X_h	The upper box bound for all state
%								variables.
%						.XT_l	The lower bound for the terminal condition
%								for all state variables.
%						.XT_h	The upper bound for the terminal condition
%								for all state variables.
%						.X0_l	The lower bound for the initial condition
%								for all state variables
%						.X0_h	The upper bound for the initial condition
%								for all state variables
%						.N_x_grid The number of grid points for each state
%								variable.
%						.grid_seed Optional non-uniform grid setup. Set the
%								n'th cell to a structure with the same
%								fields as in grid_subset to force the dpm
%								script to reduce the search space for the
%								n'th state variable. See dpm_definp.m for
%								details on how to set this up correctly.
%
%						Note; all the following fields must be matrices of
%						size [N_u, 1]
%						.U_l	The lower box bound for all inputs.
%						.U_h	The upper box bound for all inputs
%						.N_u_grid The number of grid points for each
%								control variable.
%
%						Note; the following fields must be matrices with
%							one and N_u columns respectively with an
%							arbitrary number of rows. They may be set to an
%							empty matrix if their function is not needed.
%							These fields may be useful in some applications
%							where some specific state and/or control grid
%							points should always be tested (which would
%							otherwise not occur when the grid is
%							dynamically rescaled). Points added with these
%							fields will not be rescaled with successive
%							iterations, so the total number of tested grid
%							points will be constant for all IDP iterations.
%						.X_grid_manpts	Manually forces the inclusion of
%							specific state combinations to the state grid.
%							Only available for problems with one state
%							variable, as for multi-state problems this
%							would generate a non-gridded set of tested
%							states (e.g. require using scatteredinterpolant
%							instead of griddedinterpolant), which is
%							computationally expensive to interpolate.
%						.U_grid_manpts Manually forces the inclusion of
%							specific control combinations to the control
%							grid.
%
%					.sol		All solution-related options
%						.mu_grid_dec Scaling factor for grid between each
%								successful iteration. Should be < 1. See
%								dpm_definp.m for more details.
%						.mu_grid_inc Scaling factor for grid on an
%								unsuccessful iteration. Should be > 1 and
%								significantly less than 2 - mu_grid_dec.
%								See dpm_definp.m for more details.
%						.regrid_x Set true to allow re-scaling the state
%								variable grid between iterations.
%						.regrid_u Set true to allow re-scaling the control
%								grid between iterations.
%						.iter_max Termination threshold for the maximum
%								number of iterations.
%						.fun_maxcombs Maximum number of state/control
%								combinations to include per call to the
%								system model. Note that if cpu_parallel is
%								enabled the memory usage will increase
%								linearly with the number of workers.
%						.fun	Handle to function representing system
%								model. Should be a function of form
%								[x_nn, c] = fun(x_n, u_n, t, opt) where;
%									x_n is an array with an arbitrary
%										number of rows (say n) and the i'th
%										column corresponds to the i'th
%										state variable.
%									u_n is an array with n rows and the
%										j'th column corresponds to the j'th
%										input.
%									t	is the current time
%									opt an optional model parameter
%										structure. (see mod_consts below)
%									x_nn is an array of the same size as
%										x_n and contains the state values
%										at the next time sample (i.e. the
%										result of applying u_n to x_n on a
%										row-by-row basis).
%									c	is a column array with n rows each
%										of which corresponds to the cost of
%										applying u_n to x_n.
%								Is using GPU offloading this can simply be
%								a wrapper for the fun_exp function, see
%								test_model_basic.m
%						.gpu_enable	Optional boolean, set true to enable
%								calculating the model dynamics on the local
%								GPU (if present and supported). See
%								https://se.mathworks.com/discovery/matlab-gpu.html
%								for more details on GPGPU.
%						.gpu_enter	General-purpose function hande to call
%								to process data sent to GPU. For consumer
%								GPUs this could for example be @single, as
%								they are very slow processing
%								double-precision numerical types.
%						.gpu_exit	General purpose function handle to call
%								to process data returned from the GPU. If
%								gpu_enter was set to @single, a reasonable
%								value could be to choose this to be
%								@double.
%						.fun_exp	Expanded system model function. Due to
%								language limitations in matlab, this
%								function must be of the form; [x_nn1,
%								x_nn2, ..., c] = fun(x_n1, x_n2, ..., u_n1,
%								u_n2, ..., t, opt) where the arrays x_nn,
%								x_n, and u_n in the previously described
%								.fun field are replaced with a number of
%								column vectors, where the number of
%								arguments/returned values varies with the
%								number of state and control variables. (See
%								test_model_basic_exp.m for an example).
%						.time_inv	Optional flag that, if present and set 
%								to true, indicates that the system model is
%								time invariant (i.e.
%								def_inp.sol.fun/def_inp.sol.fun_exp gives
%								identical output for all tested input
%								values t). If this is applicable and this
%								flag is set the execution time will be
%								increased very significantly. Note that
%								this requires that the state/control grid
%								is equal at all time instances, so this
%								implies that the effectiveness of the
%								range-reducing method (set by
%								inp.prb.grid_seed) and iterative dynamic
%								programming (set by inp.sol.iter_max) is
%								reduced for problems where the state and
%								controls vary significantly over time. All
%								grids will be forced to be identical for
%								all time samples.
%						.cpu_parallel Optional flag that, if present and
%								set to true, enables parallel evaluation of
%								the model during the back-calculation
%								phase. Primarily useful in cases where the
%								evaluation time for a single model call is
%								significant, e.g. large-dimensional systems
%								and/or cases where N_x_grid and N_u_grid
%								contain large values. To determine whether
%								or not to use this functionality test with
%								and without the flag set.
%						.plotfun Optional handle to a plot function called
%								on every iteration.
%						.unique_thrs Optional scalar/vector of values that,
%								if present, will activate storing the
%								relative number of one-step-suboptimal
%								controls for each state combination and
%								sample. See dpm_definp.m and
%								test_uniqueness.m for more details.
%						.interpmode Interpolation mode to use. Set to a
%								string, whose valid values depend on the
%								chosen value of N_x as follows;
%								1D; All methods supported by interp1
%								>=2D; All methods supported by the
%								griddedinterp class
%						.extrapmode Extrapolation mode to use for forward
%								calculation phase if the state ever leaves
%								the convex hull of feasible points.
%								Extrapolation is risky because there's no
%								guarantee that we'll end up inside the
%								region of feasible points again. Typically
%								set to 'none' or 'nearest' for >=2D
%								problems, inf (the numerical value, not a
%								string) or 'extrap' for 1D problems.
%						.pen_norm Norm to use for determining boundary for
%								penalizing grid points near infeasible
%								regions. Set to a string containing any of
%								the norms supported
%								by the pdist2 function.
%						.pen_thrs Threshold to apply for penalty function,
%								grid points further than this distance from
%								the nearest infeasible point, as measured
%								by the metric defined in
%								def_inp.sol.pen_norm, will be completely
%								unaffected by the penalization function.
%						.pen_fun_s Scaling penalization function; the
%								cumulative cost during the back-calculation
%								phase for grid points closer than
%								def_inp.sol.pen_thrs to any infeasible
%								point will be scaled by this value, where
%								the input to the function is the minimum
%								distance to the nearest infeasible point.
%								One example of a penalization function is
%								@(dist) (def_inp.sol.pen_thrs - dist + 1)
%								which will apply a linearly decreasing
%								penalty that is equal to
%								def_inp.sol.pen_thrs for feasible grid
%								points that are neighbors with infeasible
%								points. Set to e function that always
%								returns 1 to disable.
%						.pen_fun_a Additive penalization function; similar
%								to the above function (.pen_fun_s), but
%								instead of a multiplicative penalization
%								term this is an additive penalization. Set
%								to a function that always returns zero to
%								disable.
%						.debug	Set true to enable debugging mode, will
%								stop execution in this function on
%								error/'unexpected' results.
%						.display Set to 'iter' to display the cost for each
%								iteration in the console. Set to 'final' to
%								display the most recent cost. Set to 'none'
%								to not print any results. If field does not
%								exist will behave in the same way as with
%								'iter'.
%
%			mod_consts	Input which is directly passed to system model
%						function.
%			
%			h_iterplot	Figure handle for iteration plot if configured for
%						use.
% 
% Returns;	res		Cell array with iter_max elements, with each element
%					corresponding to the results at each grid refinement.
%					Each element contains a structure array with all
%					results, where each element corresponding to a given
%					sample. EG. element 1 corresponds to the first sample
%					in time (IE. t = 0). Each sample's fields are formatted
%					as follows;
%					
%				.x		Optimal state at sample
%				.u		Optimal control at sample
%				.c		Cost from res(n).x to res(n+1).x with control
%						signal res(n).u
%				.cum	Cumulative cost from res(1).x to res(n).x with
%						control signals res(1:n).u
%				.finitespace Range of states that was reachable with finite
%				cost during backward calculation.
%			grd		Cell array with iter_max elements, with each element
%					corresponding to the state and control grid used for
%					the each DP iteration. Each element corresponds to a
%					sample in the same way as res. Each sample's fields are
%					formatted as follows; (where the N'th column
%					corresponds to the N'th state/control variable)
%				.x_l	Lower bound for each state variable
%				.x_h	Upper bound for each state variable
%				.u_l	Lower bound for each control signal
%				.u_h	Upper bound for each control signal
%				.x		All state variable combinations
%				.u		All control combinations
%				
%			c		Identical to res(end).cum for each cell element in res
%			t		Time vector of all samples
%
%			map		Cell array with iter_max elements, with each element
%					corresponding to the map structure at each grid
%					refinement. Each element contains a structure array
%					with the full range of tested states at each sample
%					along with the lowest cumulative cost and optimal
%					control inputs at each state as generated by the
%					backward search.
%				.x	Array with all state combinations at the current
%					sample. Identical to grd.x
%				.xnn_scat Array with the the result of applying the optimal
%					control .u_o to each state combination .x.
%				.u_o Array with the optimal control signal to apply at each
%					state combination that gives the lowest cumulative
%					cost. (Note that the control signal is undefined for
%					infeasible states, IE. states where there doesn't exist
%					a set of controls that brings the state inside the
%					prescribed bounds at the terminal condition).
%				.c	The cost from the current state to the next state when
%					applying the control signal u_o
%				.cum The cumulative cost from the current state to
%					the terminal state when applying the optimal control
%					signal u_o at this (and all proceeding) samples. Note
%					that this value is interpolated for the proceeding
%					states.
% Copyright (c) 2016, Jonathan Lock
% All rights reserved.
%
% This file is part of DPM.
%
% DPM is free software: you can redistribute it and/or modify
% it under the terms of the GNU General Public License as published by
% the Free Software Foundation, either version 3 of the License, or
% (at your option) any later version.
%
% DPM is distributed in the hope that it will be useful,
% but WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
% GNU General Public License for more details.
%
% You should have received a copy of the GNU General Public License
% along with DPM.  If not, see <http://www.gnu.org/licenses/>.

	if(isempty(varargin))
		dummy = cell(1, nargout(@dpm_definp));
		[dummy{:}] = dpm_definp();
		varargout = dummy;
		return;
	elseif(numel(varargin) == 3)
		h_iterplot = varargin{3};
	end
	inp = varargin{1};
	mod_consts = varargin{2};

	%Generate shorthand notation for some variables
	N.N_t = inp.prb.N_t;							%Number of sample points
	N.N_x = inp.prb.N_x;							%Number of state variables
	N.N_u = inp.prb.N_u;							%Number of control variables
	N.T_s = inp.prb.T_s;							%Sample rate
	N.N_x_grid = inp.prb.N_x_grid;					%Number of grid points for each state variable
	N.N_u_grid = inp.prb.N_u_grid;					%Number of grid points for each control variable
	N.N_x_comb = prod(inp.prb.N_x_grid) + ... 
		size(inp.prb.X_grid_manpts, 1);				%Number of state combinations at each sample
	N.N_u_comb = prod(inp.prb.N_u_grid) + ... 
		size(inp.prb.U_grid_manpts, 1);				%Number of control combinations at each sample
	N.N_tot_comb = N.N_x_comb * N.N_u_comb;			%Number of total state/control combinations at each sample
	N.t = linspace(0, N.T_s * (N.N_t - 1), N.N_t);	%Time at each sample point
	
	%Boolean that is true if the model is time-invariant. This will change
	%how many times the model is called and significantly change how the
	%state/control grid is generated/updated.
	mdl_time_inv = isfield(inp.sol,'time_inv') && isequal(inp.sol.time_inv, true);
	
	%Controls the verbosity of status messages
	dispmode = 'iter';
	if(isfield(inp.sol, 'display'))
		dispmode = inp.sol.display;
	end
	
	%Miscellaneous initialization
	if(~strcmp(dispmode, 'none'))
		dispstat('','init');
	end
	iter = 1;
	c = zeros(1, inp.sol.iter_max);
	
	map = cell(1, inp.sol.iter_max);
	res = cell(1, inp.sol.iter_max);
	grid = cell(1, inp.sol.iter_max);
	
	%If configured for CPU-parallel operation start the pool if needed and
	%override the number of state/control configuration iterations to test
	%to be close to a multiple of the number of matlab workers.
	if(numel(inp.sol.cpu_parallel) ~= 0 && inp.sol.cpu_parallel)
		p = gcp('nocreate');
		if(isempty(p))
			p = parpool();
		end
		N.N_parpool_workers = p.NumWorkers;
		k = ceil(N.N_tot_comb/(N.N_parpool_workers*inp.sol.fun_maxcombs));
		inp.sol.fun_maxcombs = ceil(N.N_tot_comb/(N.N_parpool_workers*k));
	else
		N.N_parpool_workers = 0;
	end
	
	
	%Generate the grid structure with state and control bounds and mesh
	last_grid = repmat(struct('x_l', inp.prb.X_l, ...		%Lower state bound
				'x_h', inp.prb.X_h, ...						%Upper state bound
				'u_l', inp.prb.U_l, ...						%Lower control bound
				'u_h', inp.prb.U_h, ...						%Upper control bound
				'x', zeros([N.N_x_comb, N.N_x]), ...		%All state combinations. Each row corresponds to a single state configuration.
				'u', zeros(N.N_u_comb, N.N_u), ...			%All control combinations. Each row corresponds to a single control configuration.
				'x_man', inp.prb.X_grid_manpts, ...			%All manually added state combinations. Each row corresponds to a single state configuration.
				'u_man', inp.prb.U_grid_manpts), ...			%All manually added control combinations. Each row corresponds to a single control configuration.
			N.N_t, 1);
	
	%Check if any of the state/control variables are configured for a
	%reduced search space
	if(~isempty(inp.prb.grid_seed))
		for i = 1:length(inp.prb.grid_seed)
			seed = inp.prb.grid_seed{i};	%Shorthand dummy variable used for cleaner code
			t = linspace(0, N.T_s * (N.N_t - 1), N.N_t);
			l = interp1(seed.t, seed.center - seed.range/2, t, seed.interpmode);
			h = interp1(seed.t, seed.center + seed.range/2, t, seed.interpmode);
			for j = 1:length(last_grid)
				%Set the seed.vartype grid type and idx'th value to the
				%configured bounds
				last_grid(j).([seed.vartype '_l'])(seed.varidx) = l(j);
				last_grid(j).([seed.vartype '_h'])(seed.varidx) = h(j);
			end
		end
	end
		
	%Fill in grid based on the values we have now placed in x_l, x_h, u_l,
	%and u_h.
	last_grid = update_grid(last_grid, N, mdl_time_inv);
	
	%Flag to indicate we wish to quit due to infeasibility on the first
	%iteration
	infeas_quit = false;
	
	while(iter <= inp.sol.iter_max && infeas_quit == false)				
		
		%Some grids will result in an invalid solution -- during the
		%forward propogation phase it's possible to end up outside the
		%precalculated range genereted by the backward calculation phase.
		%Should this happen resize the grid (by slightly increasing it) and
		%retry, repeating as necessary until successful.
		res_invalid = true;
		mu = inp.sol.mu_grid_dec;
		
		if(iter > 1)
			%After the first iteration, start narrowing the range of values
			%in the state and control grids.
			cand_grid = resize_grid(last_grid, last_res, inp, mu, N, mdl_time_inv);
		else
			cand_grid = last_grid;
		end
		
		while(res_invalid && infeas_quit == false)
			%Perform back-calculation
			last_map = calc_back(cand_grid, N, mod_consts, inp, mdl_time_inv, dispmode, iter);

			%Apply forward calculation
			[cand_res, new_c, t] = calc_fw(last_map, N, mod_consts, inp, dispmode, iter);
			
			if(isfinite(new_c))
				%Our current grid gave a valid result, yay! We can now use
				%this result and possibly regrid again with a smaller grid
				res_invalid = false;
				last_grid = cand_grid;
				last_res = cand_res;
				res{iter} = last_res;
				map{iter} = last_map;
				grid{iter} = last_grid;
			else
				if(iter == 1)
					%Didn't get a feasible result on the first iteration,
					%generate an error as this is likely due a model error
					%or bad configuration.
					if(~strcmp(dispmode, 'none'))
						warning('Could not find a feasible solution!');
					end
					if inp.sol.debug
						keyboard;
					end
					map{iter} = last_map;
					res{iter} = cand_res;
					grid{iter} = last_grid;
					infeas_quit = true;
				else
					%The current grid didn't give a useful result, sucks to be
					%us. Try again with a new grid scaling factor.
					if(isnumeric(mu))
						new_mu = mu * inp.sol.mu_grid_inc;
					else
						new_mu.x = mu.x .* inp.sol.mu_grid_inc.x;
						new_mu.u = mu.u .* inp.sol.mu_grid_inc.u;
					end
					
					cand_grid = resize_grid(last_grid, last_res, inp, mu, N, mdl_time_inv);
					if(~strcmp(dispmode, 'none'))
						if(isnumeric(mu))
							str = 'Iteration %d of %d; invalid result with grid scaling factor %f, retrying with factor %f';
							if(strcmp(dispmode, 'iter'))
								dispstat(sprintf(str, iter, inp.sol.iter_max, mu, new_mu), 'keepthis');
							else
								dispstat(sprintf(str, iter, inp.sol.iter_max, mu, new_mu));
							end
						else
							str = 'Iteration %d of %d; invalid result with grid scaling factors, retrying with increased factors.';
							if(strcmp(dispmode, 'iter'))
								dispstat(sprintf(str, iter, inp.sol.iter_max), 'keepthis');
							else
								dispstat(sprintf(str, iter, inp.sol.iter_max));
							end
							
						end
					end
					mu = new_mu;
				end
			end
		end
		
		c(iter) = new_c;
		if(~strcmp(dispmode, 'none'))
			str = 'Iteration %d of %d; net cumulative cost %5e';
			if(strcmp(dispmode, 'iter'))
				dispstat(sprintf(str, iter, inp.sol.iter_max, new_c), 'keepthis');
			else
				dispstat(sprintf(str, iter, inp.sol.iter_max, new_c));
			end
			
		end
		%Draw plots
		if(isfield(inp.sol, 'plotfun') && infeas_quit == false && isa(inp.sol.plotfun, 'function_handle'))
			inp.sol.plotfun(last_res, last_grid, c, t, iter, mod_consts, h_iterplot);
			drawnow;
		end
		
		iter = iter + 1;
	end
	
	outs = {res, grid, t, c, map};
	
	varargout = cell(nargout, 1);
	for i = 1:min(nargout, 5)
		varargout{i} = outs{i};
	end

end

function map = calc_back(grd, N, mod_consts, inp, mdl_time_inv, dispmode, iter)
	%Apply a backwards DP search. All we are essentially doing here is
	%creating a map with costs to transition from any one state combination
	%at time t_n to the lowest-cost state that lies within the bounds set
	%by the terminal conditions. See the function help for a description of
	%the contents in the map structure.
	
	%Generate the entire results structure
	map = repmat(struct('x', zeros([N.N_x_comb, N.N_x]), ...
				'xnn_scat', zeros([N.N_x_comb, N.N_x]), ...
				'c', zeros(N.N_x_comb, 1), ...
				'cum', zeros(N.N_x_comb, 1), ...
				'u_o', zeros([N.N_x_comb, N.N_u]), ...
				'rel_unique_thrs', zeros([N.N_x_comb, numel(inp.sol.unique_thrs)])), ...
			N.N_t-1, 1);

	%Internal flag set true if we at some point determine that the feasible
	%space is empty. If this occurs we can stop applying the ordinary DP
	%algorithm and simply set all remaining cumulative costs to zero,
	%(potentially) saving lots of execution time
	infeas_flag = false;

	%Sweep over all time-samples and calculate the cost to move from any
	%one (gridded) state after applying the gridded control inputs. As the
	%results from this operation will generally not match the grid points
	%at the next time-sample interpolation is used to determine the
	%approximate cumulative cost from the current sample to the terminal
	%state. (One exception to this is the final sample, where we only need
	%to ensure that we end up somewhere in the range of permissible states,
	%so no interpolation is needed).
	for n_t = N.N_t-1:-1:1
		pct = (1 - n_t / (N.N_t-1)) * 100;
		if(~strcmp(dispmode, 'none'))
			dispstat(sprintf('Iteration %d of %d; running backward calculation %3.1f %%', iter, inp.sol.iter_max, pct));
		end
		
		%If the infeasibility flag has been set there doesn't exist any
		%feasible solution to bring us from where we are now to the final
		%state, so there is no point in performing the ordinary DP
		%algorithm. Simply fill the map with data to indicate this.
		if(infeas_flag)
			map(n_t).x = grd(n_t).x;
			map(n_t).c = inf * ones(size(map(n_t).c));
			map(n_t).cum = inf * ones(size(map(n_t).cum));
			continue;
		end
		
		%Determine the cost to transition from every grid point at n_t to
		%n_t+1 This will be evaluated by applying the a discretized list of
		%all possible inputs at each state point and interpolating the
		%costs at state grid points at n_t+1. State grid points outside of
		%the convex hull generated by the evaluted controls will be
		%assigned the 'infinite' cost.
		%For ease of coding, this is only partially vectorized. Each time
		%step will be handled seperately, which implies that for each
		%iteration of n_t all state and control combinations will be
		%generated simultaneously. To reduce the memory load of the call to
		%the system model this large array is (optionally) split into
		%subsections of controllable size, used when calling the system
		%model a number of times, after which is final result is assembled.
		
		%For each loop evaluation look at a given grid point at time n_t,
		%apply all possible controls, which generates a set of net states
		%at n_t+1. Interpolate the cost of moving to the gridded states
		%using the scattered results. Denote x_n as the state at sample n_t
		%and x_nn the state at sample n_t+1
		
		%If the problem is time-invariant we can skip performing a lot of
		%calculations. It is sufficient to run this segment once and then
		%simply re-use this data for successive values of n_t
		if(~mdl_time_inv || n_t == N.N_t - 1)
			%Generate array with current states. Make N_u_comb copies of each
			%row (as each row contains a single state combination).
			x_n_iter = arrayfun(@(x) repmat(x, N.N_u_comb, 1), grd(n_t).x, 'un', false);
			x_n_iter = cell2mat(x_n_iter);

			%Generate array with control signals to apply. As x_n is ordered as
			%[1;1;...;1;2;2;...;2;...] u_n should be ordered as
			%[1;2;3...;1;2;3...]
			u_n_iter = repmat(grd(n_t).u, N.N_x_comb, 1);

			%Manually handle the case where the system model is to be computed
			%on the GPU
			if(numel(inp.sol.gpu_enable) ~= 0 && inp.sol.gpu_enable == true)
				%Set up state and control variables for GPU calculation. Create
				%cell array with state/control, where each cell contains all
				%combinations of a given state/control variable. In this case
				%this is equivalent to one cell per column in x_n and u_n.
				x_g_iter = cellfun(@gpuArray, num2cell(inp.sol.gpu_enter(x_n_iter),1), 'un', false);
				u_g_iter = cellfun(@gpuArray, num2cell(inp.sol.gpu_enter(u_n_iter),1), 'un', false);

				%Send the optional parameters, order them in alphabetical order
				%to ensure that the order the structure is created doesn't
				%influence the argument order. This will convert the optional
				%model constants to a cell array where each element contains
				%each model parameter.
				opts = num2cell(inp.sol.gpu_enter(struct2array(orderfields(mod_consts))));
				opts = cellfun(@gpuArray, opts, 'un', false);

				t_g = gpuArray(inp.sol.gpu_enter(N.t(n_t)));

				%Allocate space to store result in
				%scat_x_nn_g = cellfun(@gpuArray, num2cell(inp.sol.gpu_enter(zeros(size(x_g{1},1), size(x_g,2))), 1), 'un', false);

				%Compute model dynamics. Re-use the current state memory
				%elements (x_g) to store the model output.
				[x_g_iter{:}, scat_c_g] = arrayfun(inp.sol.fun_exp, x_g_iter{:}, u_g_iter{:}, t_g, opts{:});

				%Move results back to CPU
				scat_x_nn_iter = inp.sol.gpu_exit(gather([x_g_iter{:}]));
				scat_c_iter = inp.sol.gpu_exit(gather(scat_c_g));
			else
				%Perform model call on CPU, possibly in parallel
				n_it = ceil(N.N_tot_comb/inp.sol.fun_maxcombs);
				
				%Allocate reduction variables for storing model results
				scat_x_nn_iter = zeros(size(x_n_iter));
				scat_c_iter = zeros(size(x_n_iter, 1), 1);
				parfor_size_x_nn = size(scat_x_nn_iter);
				parfor_size_c = size(scat_c_iter);
				
				parfor (k = 1 : n_it, N.N_parpool_workers)	%N_parpool_workers will be zero if cpu_parallel is disabled -> parfor will run locally
					%Generate indices of state/control combinations to test
					%for this iteration
					idx_call = (1:inp.sol.fun_maxcombs) + (k-1) * inp.sol.fun_maxcombs; %#ok<PFBNS>
					%Remove any residual elements on the last iteration
					idx_call(idx_call > N.N_tot_comb) = []; %#ok<PFBNS>
					%Call the model function
					[scat_x_nn_k, scat_c_k] = inp.sol.fun(x_n_iter(idx_call,:), u_n_iter(idx_call,:), N.t(n_t), mod_consts); %#ok<PFBNS>
					
					%Place the result in a zero vector in the correct
					%location. Use scat_x_nn_iter and scat_c_iter as
					%reduction variables
					dummy_x = zeros(parfor_size_x_nn);
					dummy_c = zeros(parfor_size_c);
					dummy_x(idx_call,:) = scat_x_nn_k;
					dummy_c(idx_call,:) = scat_c_k;
					scat_x_nn_iter = scat_x_nn_iter + dummy_x;
					scat_c_iter = scat_c_iter + dummy_c;
				end
			end
		end
		
		%Create copies of all variables generated by the model call that
		%will be used.
		scat_x_nn = scat_x_nn_iter;
		scat_c = scat_c_iter;
		x_n = x_n_iter;
		u_n = u_n_iter;
		
		%Ensure any nan and/or +/-inf are set to the internal 'inf'
		%representation
		scat_c(~isfinite(scat_c)) = inf;
		
		%Force state variable bounds to be respected
		scat_c(any(scat_x_nn < repmat(inp.prb.X_l.', N.N_u_comb * N.N_x_comb, 1), 2) | any(scat_x_nn > repmat(inp.prb.X_h.', N.N_u_comb * N.N_x_comb, 1), 2)) = inf;
		if(n_t ~= N.N_t - 1)
			%At all samples other than the final sample, also require
			%the the state variables to lie within the search space (IE
			%grid range) we will look at at the next sample. We require
			%this as we otherwise won't be able to interpolate useful
			%values for the cumulative cost during the backward
			%calculation and, similarly, won't be able to generate a
			%useful state trajectory during the foward calculation.
			scat_c(any(scat_x_nn < repmat(grd(n_t+1).x_l.', N.N_u_comb * N.N_x_comb, 1), 2) | any(scat_x_nn > repmat(grd(n_t+1).x_h.', N.N_u_comb * N.N_x_comb, 1), 2)) = inf;
		end

		%Force control variable bounds to be respected
		scat_c(any(u_n < repmat(inp.prb.U_l.', N.N_u_comb * N.N_x_comb, 1), 2) | any(u_n > repmat(inp.prb.U_h.', N.N_u_comb * N.N_x_comb, 1), 2)) = inf;

		if(n_t == N.N_t-1)
			%Force the terminal condition to be respected
			scat_c(any(scat_x_nn < repmat(inp.prb.XT_l.', N.N_u_comb * N.N_x_comb, 1), 2) | any(scat_x_nn > repmat(inp.prb.XT_h.', N.N_u_comb * N.N_x_comb, 1), 2)) = inf;
		end
		if(n_t == 1)
			%Force the initial condition to be respected
			scat_c(any(x_n  < repmat(inp.prb.X0_l.', N.N_u_comb * N.N_x_comb, 1), 2) | any(x_n  > repmat(inp.prb.X0_h.', N.N_u_comb * N.N_x_comb, 1), 2)) = inf;
		end
		
		%At this point we have determined the cost to transition from
		%all current states to several other (non-gridded) states. Now we
		%need to look at each state combination individually and determine
		%the best control signal to apply. For coding simplicity this will
		%be done on a state-by-state basis using a loop. (Hopefully) this
		%will not adversely affect performance because the call to the
		%system model is far more expensive than this loop.
		
		for k = 1:N.N_x_comb
			
			%Generate state, control, and cost arrays for the current state
			%combination looked at
			comb_idx = (1:N.N_u_comb) + (k-1)*N.N_u_comb;
			scat_c_k = scat_c(comb_idx,:);
			scat_x_nn_k = scat_x_nn(comb_idx,:);
			x_n_k = x_n(comb_idx,:);
			u_n_k = u_n(comb_idx,:);
			
		
			%Now we can simply mark the the optimal control vector at this grid
			%point (u_opt at x_n) as the element from u_n that gives the lowest
			%cumulative cost, which will be defined as cost for the current
			%sample added with the stored cumulative cost at the grid points at
			%the next time-step. However, in general scat_x_nn won't match our
			%gridded state variables, so interpolate the cumulative cost at the
			%next time step about our calculated points scat_x_nn.

			if(n_t == N.N_t - 1)
				%If we're at the last sample, simply minimize the
				%cost for the current sample
				tot_c = scat_c_k;
				[net_cum_cost, minidx] = min(tot_c);
			else
				%If we're not at the last sample, determine the cumulative
				%cost by adding the sample cost from x_n to scat_x_nn with
				%the interpolated cumulative cost from scat_x_nn to the
				%final sample.

				if(N.N_x == 1)
					cum_c = interp1(map(n_t+1).x, map(n_t+1).cum, scat_x_nn_k,  inp.sol.interpmode, inp.sol.extrapmode);
				else
					x_temp = cell(N.N_x, 1);
					for j=1:N.N_x
						x_temp{j} = reshape(map(n_t+1).x(:,j), inp.prb.N_x_grid.');
					end
					v_temp = reshape(map(n_t+1).cum, inp.prb.N_x_grid.');
					F = griddedInterpolant(x_temp{:}, v_temp, inp.sol.interpmode, inp.sol.extrapmode);
					%Manually execute the following section to plot the
					%gridded and scattered data for a two-dimensional
					%problem
					if false
						figure(); %#ok<UNRCH>
						fin_idx = isfinite(map(n_t+1).cum);
						scatter(map(n_t+1).x(fin_idx,1), map(n_t+1).x(fin_idx,2), [], map(n_t+1).cum(fin_idx), 'filled');
						hold on;
						scatter(map(n_t+1).x(~fin_idx,1), map(n_t+1).x(~fin_idx,2), 'd', 'MarkerEdgeColor', 'r', 'MarkerFaceColor', [1, .5, .5]);
						scatter(scat_x_nn_k(:,1), scat_x_nn_k(:,2), [], scat_c_k, 'p');
						scatter(x_n_k(1,1), x_n_k(1,2), 100, 'd');
						legend('Valid', 'Inval', 'Scattered next states','Current state');
						grid on;
					end
					cum_c = F(scat_x_nn_k);
					cum_c(~isfinite(cum_c)) = inf;
				end

				%The total cost is simply the cumulative cost from the next
				%sample to the end added with the interpolated cost from
				%the current to the next sample.
				tot_c = scat_c_k + cum_c;
				
				%Find the best control to apply by selecting the smallest
				%total cost.
				[net_cum_cost, minidx] = min(tot_c);
			end
			
			if(~isempty(inp.sol.unique_thrs))
				%Look at the relative cost increase for selecting slightly
				%sub-optimal controls.
				rel_c = tot_c/net_cum_cost;
				
				for j = 1:numel(inp.sol.unique_thrs)
					if(all(isinf(tot_c)))
						n_thrs = nan;	%Manually handle case where there are no feasible controls
					else
						n_thrs = (sum(rel_c <= (1 + inp.sol.unique_thrs(j))) - 1) / length(rel_c);
						n_thrs = max(0, n_thrs);
					end
					map(n_t).rel_unique_thrs(k,j) = n_thrs;
				end
			end
			
			%Save the state we started in
			map(n_t).x(k,:) = x_n_k(1,:);

			if(isfinite(net_cum_cost))
				%We found a finite cost from the current state, yay!

				%Save the control signal used to get from where we are to the
				%cheapest state position at t_{n+1}
				map(n_t).u_o(k,:) = u_n_k(minidx,:);

				%Save where we ended up after applying u_o to  x
				map(n_t).xnn_scat(k,:) = scat_x_nn_k(minidx,:);

				%Store the cost from x_n after applying the best control
				%signal u_o
				map(n_t).c(k) = scat_c_k(minidx);
			else
				%We couldn't find any way of getting from the current state
				%to a finite state =(
				%Arbitrarily set the optimal control to all zeros and the
				%next state to the current state, and set the sample cost to
				%inf.
				map(n_t).u_o(k,:) = zeros(size(u_n_k(1,:)));
				map(n_t).xnn_scat(k,:) = x_n_k(1,:);
				map(n_t).c(k) = inf;
			end

			%Store the cumulative cost 
			map(n_t).cum(k) = net_cum_cost;
		
		end
		
		%Manually execute the following lines to plot a detailed map of the
		%results from the current time step (for a 2-state system)
		if false
			figure(); %#ok<UNRCH>
			fin_idx = isfinite(map(n_t).cum);
			scatter(map(n_t).x(fin_idx,1), map(n_t).x(fin_idx,2), [], map(n_t).cum(fin_idx), 'filled');
			hold on;
			scatter(map(n_t).x(~fin_idx,1), map(n_t).x(~fin_idx,2), 'd', 'MarkerEdgeColor', 'r', 'MarkerFaceColor', [1, .5, .5]);
			arrow(map(n_t).x, map(n_t).xnn_scat, 'length', 10);
			if(n_t ~= N.N_t -1)
				fin_idx = isfinite(map(n_t+1).cum);
				scatter(map(n_t+1).x(fin_idx,1), map(n_t+1).x(fin_idx,2), [], 'd');
				legend('Feasible x', 'Infeasible x', 'x opt at next sample', 'Feasible x at next sample');
			else
				legend('Valid x', 'Invalid x', 'x opt at next sample');
			end
			grid on;
		end
		
		%Add a penalization term for all states that are 'close enough' to
		%infeasibility. This is used to increase the probability of
		%getting a feasible solution during the fordward-calculation phase.
		%Note that though this may generate a sub-optimal trajectory (for
		%example, this will be sub-optimal if the optimal trajectory
		%follows the edge of infeasibility) the deviation from the optimal
		%trajectory will asymptotically go to zero with successive
		%iterations and grid reductions. (As we're penalizing the state
		%combinations in the search grid that are close to the infeasible
		%states).
		
		%Generate a cell array with the index of each element in map.cum
		foo = cell(N.N_x, 1);
		for k=1:N.N_x
			foo{k} = 0:1:(N.N_x_grid(k)-1);
		end
		
		coords = cell(N.N_x, 1);
		%Coords will now be formatted in the same way as the grid generated
		%for map.x, and by construction also map.cum
		[coords{:}] = ndgrid(foo{:});
		
		%As we've converted map.cum to vector format, do the same with the
		%coordinates we've just generated
		foo = cellfun(@(x) x(:), coords, 'un', false);
		foo = [foo{:}];
		
		%Foo is now a cell array with N.N_x elements, where each element
		%corresponds to the values of the i'th dimension of all elements in
		%the grid.
		%We now want to find the minimum distance (which will then be
		%expressed as a nunber of grid entries) between each finite
		%cumulative cost and each non-finite cumulative cost, and finally
		%penalize the cumulative cost for elements that are 'too close' to
		%the non-finite costs.
		
		inf_idx = ~isfinite(map(n_t).cum);
		
		pen_scale = ones(size(map(n_t).cum));
		pen_offset = zeros(size(map(n_t).cum));
		
		inf_pos = foo(inf_idx, :);
		fin_pos = foo(~inf_idx, :);
		
		dist = pdist2(inf_pos, fin_pos, inp.sol.pen_norm, 'smallest', 1).';
		
		pen_idx = dist < inp.sol.pen_thrs;
		
		pen_fac = inp.sol.pen_fun_s(dist(pen_idx));
		pen_ofs = inp.sol.pen_fun_a(dist(pen_idx));
		
		fin_scale = ones(size(fin_pos, 1), 1);
		fin_offset = zeros(size(fin_pos, 1), 1);
		fin_scale(pen_idx) = pen_fac;
		fin_offset(pen_idx) = pen_ofs;
		
		pen_scale(~inf_idx) = fin_scale;
		pen_offset(~inf_idx) = fin_offset;
		
		map(n_t).cum = map(n_t).cum .* pen_scale + pen_offset;
		
		map(n_t).cum(~isfinite(map(n_t).cum)) = inf;
		
		if false
			%Debugging plot for the two-dimensional case
			figure(); %#ok<UNRCH>
			feas_x = map(n_t).x(~inf_idx,:);
			finpen_x = isfinite(fin_scale);
			scatter(feas_x(finpen_x, 1), feas_x(finpen_x, 2), [], fin_scale(finpen_x), 'filled');
			hold on;
			scatter(feas_x(~finpen_x, 1), feas_x(~finpen_x, 2), [], fin_scale(~finpen_x), 'd', 'filled');
			scatter(map(n_t).x(inf_idx,1), map(n_t).x(inf_idx,2), [], 'rd', 'filled');
			legend('feasible, finite penality', 'feasible, infinite penalty', 'infeasible');
			colorbar();
			title('Penalization factors for all grid points');
		end
		
		if(all(~isfinite(map(n_t).cum)))
			infeas_flag = true;
		end
		
	end
end

function [res, c, t] = calc_fw(map, N, mod_consts, inp, dispmode, iter)
%Start from x_0 and find the lowest cost path that reaches the end
	res = repmat(struct('x', zeros([1, N.N_x]), ...
						'u', zeros([1, N.N_u]), ...
						'c', zeros([1, 1]), ...
						'cum', zeros([1, 1])), ...
				N.N_t, 1);
			
	t = linspace(0, inp.prb.T_s * (inp.prb.N_t - 1), inp.prb.N_t);

	for n_t = 1:N.N_t-1
		pct = n_t / (N.N_t-1) * 100;
		if(~strcmp(dispmode, 'none'))
			dispstat(sprintf('Iteration %d of %d; running forward calculation %3.1f %%', iter, inp.sol.iter_max, pct));
		end
		%All we really need to do here is step through all time samples,
		%starting from the first with lowest cumulative cost, and at each
		%sample apply the stored optimal control input u_o. As we won't
		%generally find ourselves exactly on a state/control grid point,
		%determine the control signal to use by interpolating a control
		%from the nearby region.
		
		if(n_t == 1)
			%Find the first state to start from by selecting among the range of
			%valid states that will result in the lowest total cost.
			[~, idx] = min(map(n_t).cum);
			%Check if there exists a finite feasible cost. If not set all
			%outputs and return
			if(isfinite(map(n_t).cum(idx)))
				u_o = map(n_t).u_o(idx,:);		%Select the optimal control signal to apply
				x_o = map(n_t).x(idx,:);		%Select the optimal state to start from
			else
				%No valid control exists, set all results to nan and bug out
				for k = 1:length(res)
					res(k) = structfun(@(x) x*nan, res(k), 'un', false);
				end
				c = nan;
				return;
			end
		else
			%From the current state, find the optimal control signal to
			%apply by interpolating among the stored states.
			x_o = next_state;
			if(N.N_x == 1)
				u_o = interp1(map(n_t).x, map(n_t).u_o, x_o,  inp.sol.interpmode, inf);
			else
				x_temp = cell(N.N_x, 1);
				for j=1:N.N_x
					x_temp{j} = reshape(map(n_t).x(:,j), inp.prb.N_x_grid.');
				end

				for idx=1:N.N_u
					v_temp = reshape(map(n_t).u_o(:,idx), inp.prb.N_x_grid.');
					F = griddedInterpolant(x_temp{:}, v_temp, inp.sol.interpmode, inp.sol.extrapmode);
					u_o(:,idx) = F(x_o);
				end

				if false
					%Optionally manually plot the gridded and stored map points and
					%the state we ended up in where we want to interpolate a
					%trajectory
					c_temp = reshape(map(n_t).cum, inp.prb.N_x_grid.'); %#ok<UNRCH>

					F = griddedInterpolant(x_temp, y_temp, c_temp, inp.sol.interpmode, 'none');
					c_interp = F(x_o);

					figure();
					infidx = ~isfinite(c_temp);
					scatter(x_temp(infidx), y_temp(infidx), 'd', 'MarkerEdgeColor', 'r', 'MarkerFaceColor', [1, .5, .5]);
					hold on;
					scatter(x_temp(~infidx), y_temp(~infidx), [], c_temp(~infidx), 'filled');
					scatter(x_o(1), x_o(2), 'p');
					legend('inval', 'valid', 'target');
				end
			end
		end

		[next_state, c] = inp.sol.fun(x_o, u_o, N.t(n_t), mod_consts);
		
		res(n_t).x = x_o;
		res(n_t).u = u_o;
		res(n_t).c = c;
		if(n_t == 1)
			res(n_t).cum = c;
		else
			res(n_t).cum = res(n_t - 1).cum + c;
		end

		temp = map(n_t).x(isfinite(map(n_t).cum), :);
		res(n_t).finitespace = [min(temp, [], 1), max(temp, [], 1)];

		if(n_t == N.N_t - 1)
			%Manually add a data point for the final state
			res(N.N_t).x = next_state;
		end
	end

	c = res(end-1).cum;
end


function new_grd = resize_grid(grd, res, inp, mu, N, mdl_time_inv)
	%Center the new grid values about the last calculated solution,
	%reducing the total extent of the range by mu_grid, while ensuring the
	%grid range remains within the lower and upper bounds.
	new_grd = grd;
	for k=1:N.N_t
		if(inp.sol.regrid_x)
			if(isnumeric(mu))
				thismu = mu;
			else
				thismu = mu.x;
			end
			%The new extent for the grid
			range_x = (grd(k).x_h - grd(k).x_l) .* thismu; 
			
			%Set the initial upper and lower grid bounds by centering the
			%grid about the last result
			new_grd(k).x_h = res(k).x.' + 1/2 * range_x;
			new_grd(k).x_l = res(k).x.' - 1/2 * range_x;
			
			%The upper and lower grid bounds limited by the initial problem
			%constraints
			x_h_b = inp.prb.X_h;
			x_l_b = inp.prb.X_l;
			
			%If centering the new grid about the previous result violates
			%one and only one of the original problem constraints offset
			%the new grid range to lie in the original constraints.
			%Don't apply this limitation if both constraints are violated
			%as this can only occur if 'thismu' is positive, implying that
			%an iteration failed to converge and setting the grid extent to
			%the initial constraints would therefore re-create the same
			%conditions as the very first IDP iteration, which would in
			%turn imply a never-ending cyclic grid size pattern.
			
			x_h_violate = new_grd(k).x_h > x_h_b;
			x_l_violate = new_grd(k).x_l < x_l_b;
			
			for l=1:N.N_x
				if(xor(x_l_violate(l), x_h_violate(l)))
					%One but not both constraints are violated for the l'th
					%state variable
					if(new_grd(k).x_l(l) < x_l_b(l))
						new_grd(k).x_l(l) = x_l_b(l);
						new_grd(k).x_h(l) = x_l_b(l) + range_x(l);
					else
						%Else high bound is violated
						new_grd(k).x_h(l) = x_h_b(l);
						new_grd(k).x_l(l) = x_h_b(l) - range_x(l);
					end
				end
			end
		end

		if(inp.sol.regrid_u)
			if(isnumeric(mu))
				thismu = mu;
			else
				thismu = mu.u;
			end
			range_u = (grd(k).u_h - grd(k).u_l) .* thismu;
			
			%Apply the same rules to the control grid extent
			new_grd(k).u_h = res(k).u.' + 1/2 * range_u;
			new_grd(k).u_l = res(k).u.' - 1/2 * range_u;
			
			u_h_b = inp.prb.U_h;
			u_l_b = inp.prb.U_l;
			
			u_h_violate = new_grd(k).u_h > u_h_b;
			u_l_violate = new_grd(k).u_l < u_l_b;
			
			for l=1:N.N_u
				if(xor(u_l_violate(l), u_h_violate(l)))
					%One but not both constraints are violated for the l'th
					%control variable
					if(new_grd(k).u_l(l) < u_l_b(l))
						new_grd(k).u_l(l) = u_l_b(l);
						new_grd(k).u_h(l) = u_l_b(l) + range_u(l);
					else
						%Else high bound is violated
						new_grd(k).u_h(l) = u_h_b(l);
						new_grd(k).u_l(l) = u_h_b(l) - range_u(l);
					end
				end
			end
			
		end
	end
	new_grd = update_grid(new_grd, N, mdl_time_inv);
end

function grd = update_grid(grd, N, mdl_time_inv)
	%Generate grid entries based on the specified grid bounds for each
	%state/control variable	
	if(mdl_time_inv)
		%Model is assumed to be time-invariant, so the grid must be chosen
		%to be identical at every sample. This means we need to check the
		%required range of each state/control variable for each sample and
		%make the grid cover at least this range, possibly altering the
		%requested grid extents
		x_l = min(cat(2,grd(:).x_l),[],2);
		x_h = max(cat(2,grd(:).x_h),[],2);
		u_l = min(cat(2,grd(:).u_l),[],2);
		u_h = max(cat(2,grd(:).u_h),[],2);
		
		for k = 1:N.N_t
			grd(k).x_l = x_l;
			grd(k).x_h = x_h;
			grd(k).u_l = u_l;
			grd(k).u_h = u_h;
			
		end
	end
	
	for k = 1:N.N_t
		x = arrayfun(@(l, h, n) linspace(l, h, n), grd(k).x_l, grd(k).x_h, N.N_x_grid, 'un', false);
		u = arrayfun(@(l, h, n) linspace(l, h, n), grd(k).u_l, grd(k).u_h, N.N_u_grid, 'un', false);
		grid_x = cell(1, N.N_x);
		grid_u = cell(1, N.N_u);
		[grid_x{:}] = ndgrid(x{:});
		[grid_u{:}] = ndgrid(u{:});
		dummy_x = cat(N.N_x+1, grid_x{:});
		dummy_u = cat(N.N_u+1, grid_u{:});
		grd(k).x = [grd(k).x_man; reshape(dummy_x, [], N.N_x)];
		grd(k).u = [grd(k).u_man; reshape(dummy_u, [], N.N_u)];
	end
end