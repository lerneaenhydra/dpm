function varargout = dpm(varargin)
% DPM(inp, mod_consts) Simple dynamic programming solver for arbitrary
% continuous-valued problems represented with ODEs. Solves problems of the
% form:
%	
%	min C(x(k), u(k)) for k = [0, K]
%
%	subject to
%
%	x(k+t) = f(x(k), u(k))
%
% where x(k) and u(k) represent the sampled state and control variable
% values at some time k.
%
% This dynamic programming solver differs from the textbook DP solver in
% the following ways;
%	- The search range for state and control variables is iteratively
%	decreased following a mostly typical iterative dynamic programming
%	(IDP) implementation. This solver differs from the typical IDP solver
%	by allowing the grid size to increase slightly in the event that the
%	feasible solution can be found after decreaseing the search grid
%	extents.
%	- For loosely coupled multidimensional problems, an approximate
%	solution generated by some n-1-dimensional problem can be used to
%	reduce the search space for the n-dimensional problem, significantly
%	reducing the time needed to arrive to a solution.
%	- An optional regularization term can by added and/or scale the cost
%	function for tested states that are within some adjustable distance
%	to infeasible state(s). This regularization term sigificanlty increases
%	the ability for the DP solver to generate a feasible control
%	trajectory for applications where the optimal control trajectory lies
%	along a boundary of infeasibility (eg. bang-bang control).
%
% Use the call 'inp = dpm()' to return a structure containing the fields
% required by the dpm solver.
%
% Use the call '[inp, grid_subset] = dpm()' to return the previously
% described structure as well as an empty structure of the form used to
% configure limiting the search space for grid variable(s).
%
% Use the call [res, grid, t, c, map] = dpm(inp, mod_consts, h_iterplot)
% to solve the dynamic programming problem.
%
% Inputs;	inp		Structure with all configuration for the DP solver.
%					Must contain the following fields;
%
%					.prb		All problem-related options
%						.T_s	The sample period for the system to solve
%						.N_x	The number of state variables
%						.N_u	The number of control variables
%						.N_t	The number of samples to process. This
%								gives the total simulation time by T_s *
%								(N_t - 1).
%						.dp_inf	Value used to represent an infeasible
%								state/control combination. Must be at least
%								as large as the maximum cost from one
%								sample to the next for any valid 
%								state/control input.
%
%						Note; all the following fields must be matrices of
%						size [N_x, 1].
%						.X_l	The lower box bound for all state
%								variables.
%						.X_h	The upper box bound for all state
%								variables.
%						.XT_l	The lower bound for the terminal condition
%								for all state variables.
%						.XT_h	The upper bound for the terminal condition
%								for all state variables.
%						.X0_l	The lower bound for the initial condition
%								for all state variables
%						.X0_h	The upper bound for the initial condition
%								for all state variables
%						.N_x_grid The number of grid points for each state
%								variable.
%
%						Note; all the following fields must be matrices of
%						size [N_u, 1]
%						.U_l	The lower box bound for all inputs.
%						.U_h	The upper box bound for all inputs
%						.N_u_grid The number of grid points for each
%								control variable.
%
%					.sol		All solution-related options
%						.mu_grid_dec Scaling factor for grid between each
%								successful iteration. Should be < 1.
%						.mu_grid_inc Scaling factor for grid on an
%								unsuccessful iteration. Should be > 1 and
%								significantly less than 2 - mu_grid_dec.
%						.regrid_x Set true to allow re-scaling the state
%								variable grid between iterations.
%						.regrid_u Set true to allow re-scaling the control
%								grid between iterations.
%						.iter_max Termination threshold for the maximum
%								number of iterations.
%						.fun	Handle to function representing system
%								model.
%						.plotfun Optional handle to a plot function called
%								on every iteration.
%						.interpmode Interpolation mode to use. Set to a
%								string, whose valid values depend on the
%								chosen value of N_x as follows;
%								1D; All methods supported by interp1
%								>=2D; All methods supported by the
%								griddedinterp class
%						.extrapmode Extrapolation mode to use for forward
%								calculation phase if the state ever leaves
%								the convex hull of feasible points.
%								Extrapolation is risky because there's no
%								guarantee that we'll end up inside the
%								region of feasible points again. Typically
%								set to 'none' or 'nearest' for >=2D
%								problems, 'inf' or 'extrap' for 1D
%								problems.
%						.pen_norm Norm to use for determining boundary for
%								penalizing grid points near infeasible
%								regions. Set to a string containing any of
%								the norms supported
%								by the pdist2 function.
%						.pen_thrs Threshold to apply for penalty function,
%								grid points further than this distance from
%								the nearest infeasible point, as measured
%								by the metric defined in
%								def_inp.sol.pen_norm, will be completely
%								unaffected by the penalization function.
%						.pen_fun_s Scaling penalization function; the
%								cumulative cost during the back-calculation
%								phase for grid points closer than
%								def_inp.sol.pen_thrs to any infeasible
%								point will be scaled by this value, where
%								the input to the function is the minimum
%								distance to the nearest infeasible point.
%								One example of a penalization function is
%								@(dist) (def_inp.sol.pen_thrs - dist + 1)
%								which will apply a linearly decreasing
%								penalty that is equal to
%								def_inp.sol.pen_thrs for feasible grid
%								points that are neighbors with infeasible
%								points. Set to e function that always
%								returns 1 to disable.
%						.pen_fun_a Additive penalization function; similar
%								to the above function (.pen_fun_s), but
%								instead of a multiplicative penalization
%								term this is an additive penalization. Set
%								to a function that always returns zero to
%								disable.
%						.debug	Set true to enable debugging mode, will
%								stop execution in this function on
%								error/'unexpected' results.
%
%			mod_consts	Input which is directly passed to system model
%						function.
%			
%			h_iterplot	Figure handle for iteration plot.
% 
% Returns;	res		Cell array with iter_max elements, with each element
%					corresponding to the results at each grid refinement.
%					Each element contains a structure array with all
%					results, where each element corresponding to a given
%					sample. EG. element 1 corresponds to the first sample
%					in time (IE. t = 0). Each sample's fields are formatted
%					as follows;
%					
%				.x		Optimal state at sample
%				.u		Optimal control at sample
%				.c		Cost from res(n).x to res(n+1).x with control
%						signal res(n).u
%				.cum	Cumulative cost from res(1).x to res(n).x with
%						control signals res(1:n).u
%				.finitespace Range of states that was reachable with finite
%				cost during backward calculation.
%
%			grd		Cell array with iter_max elements, with each element
%					corresponding to the state and control grid used for
%					the each DP iteration. Each element corresponds to a
%					sample in the same way as res. Each sample's fields are
%					formatted as follows; (where the N'th column
%					corresponds to the N'th state/control variable)
%				.x_l	Lower bound for each state variable
%				.x_h	Upper bound for each state variable
%				.u_l	Lower bound for each control signal
%				.u_h	Upper bound for each control signal
%				.x		All state variable combinations
%				.u		All control combinations
%				
%			c		Identical to res(end).cum for each cell element in res
%			t		Time vector of all samples
%
%			map		Cell array with iter_max elements, with each element
%					corresponding to the map structure at each grid
%					refinement. Each element contains a structure array
%					with the full range of tested states at each sample
%					along with the lowest cumulative cost and optimal
%					control inputs at each state as generated by the
%					backward search.
%				.x	Array with all state permutations at the current
%					sample. Identical to grd.x
%				.xnn_scat Array with the the result of applying the optimal
%					control .u_o to each state permutation .x.
%				.u_o Array with the optimal control signal to apply at each
%					state combination that gives the lowest cumulative
%					cost. (Note that the control signal is undefined for
%					infeasible states, IE. states where there doesn't exist
%					a set of controls that brings the state inside the
%					prescribed bounds at the terminal condition).
%				.c	The cost from the current state to the next state when
%					applying the control signal u_o
%				.cum The cumulative cost from the current state to
%					the terminal state when applying the optimal control
%					signal u_o at this (and all proceeding) samples. Note
%					that this value is interpolated for the proceeding
%					states.
% Copyright (c) 2016, Jonathan Lock
% All rights reserved.
%
% This file is part of DPM.
%
% DPM is free software: you can redistribute it and/or modify
% it under the terms of the GNU General Public License as published by
% the Free Software Foundation, either version 3 of the License, or
% (at your option) any later version.
%
% DPM is distributed in the hope that it will be useful,
% but WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
% GNU General Public License for more details.
%
% You should have received a copy of the GNU General Public License
% along with DPM.  If not, see <http://www.gnu.org/licenses/>.

	if(isempty(varargin))
		dummy = cell(1, nargout(@dpm_definp));
		[dummy{:}] = dpm_definp();
		varargout = dummy;
		return;
	else
		inp = varargin{1};
		mod_consts = varargin{2};
		h_iterplot = varargin{3};
	end

	%Generate shorthand notation for some variables
	N.N_t = inp.prb.N_t;							%Number of sample points
	N.N_x = inp.prb.N_x;							%Number of state variables
	N.N_u = inp.prb.N_u;							%Number of control variables
	N.T_s = inp.prb.T_s;							%Sample rate
	N.N_x_grid = inp.prb.N_x_grid;					%Number of grid points for each state variable
	N.N_u_grid = inp.prb.N_u_grid;					%Number of grid points for each control variable
	N.N_x_perm = prod(inp.prb.N_x_grid);			%Number of state permutations at each sample
	N.N_u_perm = prod(inp.prb.N_u_grid);			%Number of control permutations at each sample
	N.t = linspace(0, N.T_s * (N.N_t - 1), N.N_t);	%Time at each sample point
	
	%Miscellaneous initialization
	dispstat('','init');
	iter = 1;
	c = zeros(1, inp.sol.iter_max);
	
	map = cell(1, inp.sol.iter_max);
	res = cell(1, inp.sol.iter_max);
	grid = cell(1, inp.sol.iter_max);
	
	
	%Generate the grid structure with state and control bounds and mesh
	last_grid = repmat(struct('x_l', inp.prb.X_l, ...		%Lower state bound
				'x_h', inp.prb.X_h, ...						%Upper state bound
				'u_l', inp.prb.U_l, ...						%Lower control bound
				'u_h', inp.prb.U_h, ...						%Upper control bound
				'x', zeros([N.N_x_perm, N.N_x]), ...		%All state permutations. Each row corresponds to a single state configuration.
				'u', zeros(N.N_u_perm, N.N_u)), ...			%All control permutations. Each row corresponds to a single control configuration.
			N.N_t, 1);		
	
	%Check if any of the state variables is configured for a reduced search
	%space
	if(~isempty(inp.prb.grid_seed))
		for i = 1:length(inp.prb.grid_seed)
			if(~isempty(inp.prb.grid_seed{i}))
				%If we get here, we know that the i'th state variable has a
				%configured reduced search space, so set it up now
				seed = inp.prb.grid_seed{i};	%Shorthand dummy variable used for cleaner code
				t = linspace(0, N.T_s * (N.N_t - 1), N.N_t);
				x_l = interp1(seed.t, seed.center - seed.range/2, t, seed.interpmode);
				x_h = interp1(seed.t, seed.center + seed.range/2, t, seed.interpmode);
				for j = 1:length(last_grid)
					last_grid(j).x_h(i) = x_h(j);
					last_grid(j).x_l(i) = x_l(j);
				end
			end
		end
	end
		
	%Fill in grid based on the values we have now placed in x_l, x_h, u_l,
	%and u_h.
	last_grid = update_grid(last_grid, N);
	
	%Flag to indicate we wish to quit due to infeasibility on the first
	%iteration
	infeas_quit = false;
	
	while(iter <= inp.sol.iter_max && infeas_quit == false)				
		
		%Some grids will result in an invalid solution -- during the
		%forward propogation phase it's possible to end up outside the
		%precalculated range genereted by the backward calculation phase.
		%Should this happen resize the grid (by slightly increasing it) and
		%retry, repeating as necessary until successful.
		res_invalid = true;
		mu = inp.sol.mu_grid_dec;
		
		if(iter > 1)
			%After the first iteration, start narrowing the range of values
			%in the state and control grids.
			cand_grid = resize_grid(last_grid, last_res, inp.sol, mu, N);
		else
			cand_grid = last_grid;
		end
		
		while(res_invalid && infeas_quit == false)
			%Perform back-calculation
			last_map = calc_back(cand_grid, N, mod_consts, inp);

			%Apply forward calculation
			[cand_res, new_c, t] = calc_fw(last_map, N, mod_consts, inp);
			
			if(isfinite(new_c))
				%Our current grid gave a valid result, yay! We can now use
				%this result and possibly regrid again with a smaller grid
				res_invalid = false;
				last_grid = cand_grid;
				last_res = cand_res;
				res{iter} = last_res;
				map{iter} = last_map;
				grid{iter} = last_grid;
			else
				if(iter == 1)
					%Didn't get a feasible result on the first iteration,
					%generate an error as this is likely due a model error
					%or bad configuration.
					warning('Could not find a feasible solution!');
					if inp.sol.debug
						keyboard;
					end
					map{iter} = last_map;
					res{iter} = cand_res;
					grid{iter} = last_grid;
					infeas_quit = true;
				else
					%The current grid didn't give a useful result, sucks to be
					%us. Try again with a new grid scaling factor.
					new_mu = mu * inp.sol.mu_grid_inc;
					cand_grid = resize_grid(last_grid, last_res, inp.sol, mu, N);
					dispstat(sprintf('Iteration %d of %d, invalid result with grid scaling factor %f, retrying with factor %f', iter, inp.sol.iter_max, mu, new_mu), 'keepthis');
					mu = new_mu;
				end
			end
		end
		
		c(iter) = new_c;
		
		dispstat(sprintf('Iteration %d of %d, net cumulative cost %5e', iter, inp.sol.iter_max, new_c),'keepthis');
		%Draw plots
		if(isfield(inp.sol, 'plotfun') && infeas_quit == false)
			inp.sol.plotfun(last_res, last_grid, c, t, iter, mod_consts, h_iterplot);
			drawnow;
		end
		
		iter = iter + 1;
	end
	
	outs = {res, grid, t, c, map};
	
	varargout = cell(nargout, 1);
	for i = 1:min(nargout, 5)
		varargout{i} = outs{i};
	end

end

function new_grd = resize_grid(grd, res, sol, mu, N)
	%Center the new grid values about the last calculated solution,
	%reducing the total extent of the range by mu_grid, while ensuring the
	%grid range remains within the lower and upper bounds.
	new_grd = grd;
	for k=1:N.N_t
		if(sol.regrid_x)
			range_x = (grd(k).x_h - grd(k).x_l) * mu; 
			new_grd(k).x_h = res(k).x.' + 1/2 * range_x;
			new_grd(k).x_l = res(k).x.' - 1/2 * range_x;
		end

		if(sol.regrid_u)
			range_u = (grd(k).u_h - grd(k).u_l) * mu;
			new_grd(k).u_h = res(k).u.' + 1/2 * range_u;
			new_grd(k).u_l = res(k).u.' - 1/2 * range_u;
		end
	end
	new_grd = update_grid(new_grd, N);
end

function map = calc_back(grd, N, mod_consts, inp)
	%Apply a backwards DP search. All we are essentially doing here is
	%creating a map with costs to transition from any one state combination
	%at time t_n to the lowest-cost state that lies within the bounds set
	%by the terminal conditions. See the function help for a description of
	%the contents in the map structure.
	
	%Generate the entire results structure
	map = repmat(struct('x', zeros([N.N_x_perm, N.N_x]), ...
				'xnn_scat', zeros([N.N_x_perm, N.N_x]), ...
				'c', zeros(N.N_x_perm, 1), ...
				'cum', zeros(N.N_x_perm, 1), ...
				'u_o', zeros([N.N_x_perm, N.N_u])), ...
			N.N_t-1, 1);

	%Internal flag set true if we at some point determine that the feasible
	%space is empty. If this occurs we can stop applying the ordinary DP
	%algorithm and simply set all remaining cumulative costs to zero,
	%(potentially) saving lots of execution time
	infeas_flag = false;

	%Sweep over all time-samples and calculate the cost to move from any
	%one (gridded) state after applying the gridded control inputs. As the
	%results from this operation will generally not match the grid points
	%at the next time-sample interpolation is used to determine the
	%approximate cumulative cost from the current sample to the terminal
	%state. (One exception to this is the final sample, where we only need
	%to ensure that we end up somewhere in the range of permissible states,
	%so no interpolation is needed).
	for n_t = N.N_t-1:-1:1
		pct = (1 - n_t / (N.N_t-1)) * 100;
		dispstat(sprintf('Running backward calculation %3.1f %%', pct));
		
		%If the infeasibility flag has been set there doesn't exist any
		%feasible solution to bring us from where we are now to the final
		%state, so there is no point in performing the ordinary DP
		%algorithm. Simply fill the map with data to indicate this.
		
		if(infeas_flag)
			map(n_t).x = grd(n_t).x;
			map(n_t).c = inf * ones(size(map(n_t).c));
			map(n_t).cum = inf * ones(size(map(n_t).cum));
			continue;
		end
		
		%Determine the cost to transition from every grid point at n_t to
		%n_t+1 This will be evaluated by applying the a discretized list of
		%all possible inputs at each state point and interpolating the
		%costs at state grid points at n_t+1. State grid points outside of
		%the convex hull generated by the evaluted controls will be
		%assigned the 'infinite' cost.
		%For ease of coding, only partially vectorize this. For each for
		%loop evaluation look at a given grid point at time n_t, apply all
		%possible controls, which generates a set of net states at n_t+1.
		%Interpolate the cost of moving to the gridded states using the
		%scattered results. Denote x_n as the state at sample n_t and x_nn
		%the state at sample n_t+1
		for k = 1:N.N_x_perm
			
			%As we wish to keep x_n constant, all rows of x_n should be
			%identical. Select the k'th row and replicate it to generate an
			%array of the same size.
			x_n = repmat(grd(n_t).x(k,:), N.N_u_perm, 1);

			%As we wish to sweep over the entire control grid, simply copy
			%the current grid's values
			u_n = grd(n_t).u;

			%Calculate the cost to move from x_n with controls u_n
			[scat_x_nn, scat_c] = inp.sol.fun(x_n, u_n, N.t(n_t), mod_consts);
			
			%Ensure any nan and/or +/-inf are set to the internal 'inf'
			%representation
			scat_c(~isfinite(scat_c)) = inf;

			%Force state variable bounds to be respected
			scat_c(any(scat_x_nn < repmat(inp.prb.X_l.', N.N_u_perm, 1), 2) | any(scat_x_nn > repmat(inp.prb.X_h.', N.N_u_perm, 1), 2)) = inf;
			if(n_t ~= N.N_t - 1)
				%At all samples other than the final sample, also require
				%the the state variables to lie within the search space (IE
				%grid range) we will look at at the next sample. We require
				%this as we otherwise won't be able to interpolate useful
				%values for the cumulative cost during the backward
				%calculation and, similarly, won't be able to generate a
				%useful state trajectory during the foward calculation.
				scat_c(any(scat_x_nn < repmat(grd(n_t+1).x_l.', N.N_u_perm, 1), 2) | any(scat_x_nn > repmat(grd(n_t+1).x_h.', N.N_u_perm, 1), 2)) = inf;
			end
			
			%Force control variable bounds to be respected
			scat_c(any(u_n < repmat(inp.prb.U_l.', N.N_u_perm, 1), 2) | any(u_n > repmat(inp.prb.U_h.', N.N_u_perm, 1), 2)) = inf;
			
			if(n_t == N.N_t-1)
				%Force the terminal condition to be respected
				scat_c(any(scat_x_nn < repmat(inp.prb.XT_l.', N.N_u_perm, 1), 2) | any(scat_x_nn > repmat(inp.prb.XT_h.', N.N_u_perm, 1), 2)) = inf;
			end
			if(n_t == 1)
				%Force the initial condition to be respected
				scat_c(any(x_n  < repmat(inp.prb.X0_l.', N.N_u_perm, 1), 2) | any(x_n  > repmat(inp.prb.X0_h.', N.N_u_perm, 1), 2)) = inf;
			end

			%At this point we have determined the cost to transition from
			%the current state to several other (non-gridded) states. Now
			%we can simply mark the the optimal control vector at this grid
			%point (u_opt at x_n) as the element from u_n that gives the
			%lowest cumulative cost, which will be defined as cost for the
			%current sample added with the stored cumulative cost at the
			%grid points at the next time-step. However, in general
			%scat_x_nn won't match our gridded state variables, so
			%interpolate the cumulative cost at the next time step about
			%our calculated points scat_x_nn.

			if(n_t == N.N_t - 1)
				%If we're at the last sample, simply minimize the
				%cost for the current sample
				[net_cum_cost, minidx] = min(scat_c);
			else
				%If we're not at the last sample, determine the cumulative
				%cost by adding the sample cost from x_n to scat_x_nn with
				%the interpolated cumulative cost from scat_x_nn to the
				%final sample.
				
				if(N.N_x == 1)
					cum_c = interp1(map(n_t+1).x, map(n_t+1).cum, scat_x_nn,  inp.sol.interpmode, inp.sol.extrapmode);
				else
					x_temp = cell(N.N_x, 1);
					for j=1:N.N_x
						x_temp{j} = reshape(map(n_t+1).x(:,j), inp.prb.N_x_grid.');
					end
					v_temp = reshape(map(n_t+1).cum, inp.prb.N_x_grid.');
					F = griddedInterpolant(x_temp{:}, v_temp, inp.sol.interpmode, inp.sol.extrapmode);
					%Manually execute the following section to plot the
					%gridded and scattered data for a two-dimensional
					%problem
					if false
						figure();
						fin_idx = isfinite(map(n_t+1).cum);
						scatter(map(n_t+1).x(fin_idx,1), map(n_t+1).x(fin_idx,2), [], map(n_t+1).cum(fin_idx), 'filled');
						hold on;
						scatter(map(n_t+1).x(~fin_idx,1), map(n_t+1).x(~fin_idx,2), 'd', 'MarkerEdgeColor', 'r', 'MarkerFaceColor', [1, .5, .5]);
						scatter(scat_x_nn(:,1), scat_x_nn(:,2), [], scat_c, 'p');
						scatter(x_n(1,1), x_n(1,2), 50, 'd');
						legend('Valid', 'Inval', 'Scattered next states','Current state');
						grid on;
					end
					cum_c = F(scat_x_nn);
					cum_c(~isfinite(cum_c)) = inf;
				end

				[net_cum_cost, minidx] = min(scat_c + cum_c);
			end

			%Save the state we started in
			map(n_t).x(k,:) = x_n(1,:);
			
			if(isfinite(net_cum_cost))
				%We found a finite cost from the current state, yay!

				%Save the control signal used to get from where we are to the
				%cheapest state position at t_{n+1}
				map(n_t).u_o(k,:) = u_n(minidx,:);

				%Save where we ended up after applying u_o to  x
				map(n_t).xnn_scat(k,:) = scat_x_nn(minidx,:);

				%Store the cost from x_n after applying the best control
				%signal u_o
				map(n_t).c(k) = scat_c(minidx);
			else
				%We couldn't find any way of getting from the current state
				%to a finite state =(
				%Arbitrarily set the optimal control to all zeros and the
				%next state to the current state, and set the sample cost to
				%inf.
				map(n_t).u_o(k,:) = zeros(size(u_n(1,:)));
				map(n_t).xnn_scat(k,:) = x_n(1,:);
				map(n_t).c(k) = inf;
			end

			%Store the cumulative cost 
			map(n_t).cum(k) = net_cum_cost;
			
		end
		
		%Manually execute the following lines to plot a detailed map of the
		%results from the current time step
		if false
			figure();
			fin_idx = isfinite(map(n_t).cum);
			scatter(map(n_t).x(fin_idx,1), map(n_t).x(fin_idx,2), [], map(n_t).cum(fin_idx), 'filled');
			hold on;
			scatter(map(n_t).x(~fin_idx,1), map(n_t).x(~fin_idx,2), 'd', 'MarkerEdgeColor', 'r', 'MarkerFaceColor', [1, .5, .5]);
			arrow(map(n_t).x, map(n_t).xnn_scat, 'length', 10);
			if(n_t ~= N.N_t -1)
				fin_idx = isfinite(map(n_t+1).cum);
				scatter(map(n_t+1).x(fin_idx,1), map(n_t+1).x(fin_idx,2), [], 'd');
				legend('Feasible x', 'Infeasible x', 'x opt at next sample', 'Feasible x at next sample');
			else
				legend('Valid x', 'Invalid x', 'x opt at next sample');
			end
			grid on;
		end
		
		%Add a penalization term for all states that are 'close enough' to
		%infeasibility. This is used to increase the probability of
		%getting a feasible solution during the fordward-calculation phase.
		%Note that though this may generate a sub-optimal trajectory (for
		%example, this will be sub-optimal if the optimal trajectory
		%follows the edge of infeasibility) the deviation from the optimal
		%trajectory will asymptotically go to zero with successive
		%iterations and grid reductions. (As we're penalizing the state
		%combinations in the search grid that are close to the infeasible
		%states).
		
		%Generate a cell array with the index of each element in map.cum
		foo = cell(N.N_x, 1);
		for k=1:N.N_x
			foo{k} = 0:1:(N.N_x_grid(k)-1);
		end
		
		coords = cell(N.N_x, 1);
		%Coords will now be formatted in the same way as the grid generated
		%for map.x, and by construction also map.cum
		[coords{:}] = ndgrid(foo{:});
		
		%As we've converted map.cum to vector format, do the same with the
		%coordinates we've just generated
		foo = cellfun(@(x) x(:), coords, 'un', false);
		foo = [foo{:}];
		
		%Foo is now a cell array with N.N_x elements, where each element
		%corresponds to the values of the i'th dimension of all elements in
		%the grid.
		%We now want to find the minimum distance (which will then be
		%expressed as a nunber of grid entries) between each finite
		%cumulative cost and each non-finite cumulative cost, and finally
		%penalize the cumulative cost for elements that are 'too close' to
		%the non-finite costs.
		
		inf_idx = ~isfinite(map(n_t).cum);
		
		pen_scale = ones(size(map(n_t).cum));
		pen_offset = zeros(size(map(n_t).cum));
		
		inf_pos = foo(inf_idx, :);
		fin_pos = foo(~inf_idx, :);
		
		dist = pdist2(inf_pos, fin_pos, inp.sol.pen_norm, 'smallest', 1).';
		
		pen_idx = dist < inp.sol.pen_thrs;
		
		pen_fac = inp.sol.pen_fun_s(dist(pen_idx));
		pen_ofs = inp.sol.pen_fun_a(dist(pen_idx));
		
		fin_scale = ones(size(fin_pos, 1), 1);
		fin_offset = zeros(size(fin_pos, 1), 1);
		fin_scale(pen_idx) = pen_fac;
		fin_offset(pen_idx) = pen_ofs;
		
		pen_scale(~inf_idx) = fin_scale;
		pen_offset(~inf_idx) = fin_offset;
		
		map(n_t).cum = map(n_t).cum .* pen_scale + pen_offset;
		
		map(n_t).cum(~isfinite(map(n_t).cum)) = inf;
		
		if false
			%Debugging plot for the two-dimensional case
			figure();
			feas_x = map(n_t).x(~inf_idx,:);
			finpen_x = isfinite(fin_scale);
			scatter(feas_x(finpen_x, 1), feas_x(finpen_x, 2), [], fin_scale(finpen_x), 'filled');
			hold on;
			scatter(feas_x(~finpen_x, 1), feas_x(~finpen_x, 2), [], fin_scale(~finpen_x), 'd', 'filled');
			scatter(map(n_t).x(inf_idx,1), map(n_t).x(inf_idx,2), [], 'rd', 'filled');
			legend('feasible, finite penality', 'feasible, infinite penalty', 'infeasible');
			colorbar();
			title('Penalization factors for all grid points');
		end
		
		if(all(~isfinite(map(n_t).cum)))
			infeas_flag = true;
		end
		
	end
end

function [res, c, t] = calc_fw(map, N, mod_consts, inp)
%Start from x_0 and find the lowest cost path that reaches the end
	res = repmat(struct('x', zeros([1, N.N_x]), ...
						'u', zeros([1, N.N_u]), ...
						'c', zeros([1, 1]), ...
						'cum', zeros([1, 1])), ...
				N.N_t, 1);

	for n_t = 1:N.N_t-1
		pct = n_t / (N.N_t-1) * 100;
		dispstat(sprintf('Running forward calculation %3.1f %%', pct));
		%All we really need to do here is step through all time samples,
		%starting from the first with lowest cumulative cost, and at each
		%sample apply the stored optimal control input u_o. As we won't
		%generally find ourselves exactly on a state/control grid point,
		%determine the control signal to use by interpolating a control
		%from the nearby region.
		
		if(n_t == 1)
			%Find the first state to start from by selecting among the range of
			%valid states that will result in the lowest total cost.
			[~, idx] = min(map(n_t).cum);
			u_o = map(n_t).u_o(idx,:);		%Select the optimal control signal to apply
			x_o = map(n_t).x(idx,:);		%Select the optimal state to start from
		else
			%From the current state, find the optimal control signal to
			%apply by interpolating among the stored states.
			x_o = next_state;
			if(N.N_x == 1)
				u_o = interp1(map(n_t).x, map(n_t).u_o, x_o,  inp.sol.interpmode, inf);
			else
				x_temp = cell(N.N_x, 1);
				for j=1:N.N_x
					x_temp{j} = reshape(map(n_t).x(:,j), inp.prb.N_x_grid.');
				end

				for idx=1:N.N_u
					v_temp = reshape(map(n_t).u_o(:,idx), inp.prb.N_x_grid.');
					F = griddedInterpolant(x_temp{:}, v_temp, inp.sol.interpmode, inp.sol.extrapmode);
					u_o(:,idx) = F(x_o);
				end

				if false
					%Optionally manually plot the gridded and stored map points and
					%the state we ended up in where we want to interpolate a
					%trajectory
					c_temp = reshape(map(n_t).cum, inp.prb.N_x_grid.');

					F = griddedInterpolant(x_temp, y_temp, c_temp, inp.sol.interpmode, 'none');
					c_interp = F(x_o);

					figure();
					infidx = ~isfinite(c_temp);
					scatter(x_temp(infidx), y_temp(infidx), 'd', 'MarkerEdgeColor', 'r', 'MarkerFaceColor', [1, .5, .5]);
					hold on;
					scatter(x_temp(~infidx), y_temp(~infidx), [], c_temp(~infidx), 'filled');
					scatter(x_o(1), x_o(2), 'p');
					legend('inval', 'valid', 'target');
				end
			end
		end

		[next_state, c] = inp.sol.fun(x_o, u_o, N.t(n_t), mod_consts);
		
		res(n_t).x = x_o;
		res(n_t).u = u_o;
		res(n_t).c = c;
		if(n_t == 1)
			res(n_t).cum = c;
		else
			res(n_t).cum = res(n_t - 1).cum + c;
		end

		temp = map(n_t).x(isfinite(map(n_t).cum), :);
		res(n_t).finitespace = [min(temp, [], 1), max(temp, [], 1)];

		if(n_t == N.N_t - 1)
			%Manually add a data point for the final state
			res(N.N_t).x = next_state;
		end
	end

	c = res(end-1).cum;
	t = linspace(0, inp.prb.T_s * (inp.prb.N_t - 1), inp.prb.N_t);
end

function grd = update_grid(grd, N)
	for k = 1:N.N_t
		x = arrayfun(@(l, h, n) linspace(l, h, n), grd(k).x_l, grd(k).x_h, N.N_x_grid, 'un', false);
		u = arrayfun(@(l, h, n) linspace(l, h, n), grd(k).u_l, grd(k).u_h, N.N_u_grid, 'un', false);
		grid_x = cell(1, N.N_x);
		grid_u = cell(1, N.N_u);
		[grid_x{:}] = ndgrid(x{:});
		[grid_u{:}] = ndgrid(u{:});
		dummy_x = cat(N.N_x+1, grid_x{:});
		dummy_u = cat(N.N_u+1, grid_u{:});
		grd(k).x = reshape(dummy_x, [], N.N_x);
		grd(k).u = reshape(dummy_u, [], N.N_u);
	end
end